use serde::{Deserialize, Serialize};
use tokio::time::{sleep, Duration};
use tracing::{debug, error, info, warn};

/// Estrutura para uma mensagem do ChatGPT
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ChatMessage {
    pub role: String,
    pub content: String,
}

/// Estrutura para a requisi√ß√£o do ChatGPT
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ChatRequest {
    pub model: String,
    pub messages: Vec<ChatMessage>,
    pub temperature: f32,
    pub max_tokens: Option<u32>,
}

/// Estrutura para a resposta do ChatGPT
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ChatResponse {
    pub id: String,
    pub object: String,
    pub created: u64,
    pub model: String,
    pub choices: Vec<ChatChoice>,
    pub usage: Usage,
}

/// Estrutura para uma escolha da resposta
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ChatChoice {
    pub index: u32,
    pub message: ChatMessage,
    pub finish_reason: Option<String>,
}

/// Estrutura para o uso de tokens
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Usage {
    pub prompt_tokens: u32,
    pub completion_tokens: u32,
    pub total_tokens: u32,
}

use crate::types::*;

/// Cliente para integra√ß√£o com ChatGPT
pub struct ChatGPTClient {
    client: reqwest::Client,
    config: crate::config::Config,
    rate_limiter: tokio::sync::Mutex<()>,
}

impl ChatGPTClient {
    /// Cria um novo cliente ChatGPT
    pub fn new(config: crate::config::Config) -> crate::Result<Self> {
        let client = reqwest::Client::builder()
            .timeout(Duration::from_secs(config.timeout_seconds))
            .build()
            .map_err(|e| crate::Error::Http(e))?;

        Ok(Self {
            client,
            config,
            rate_limiter: tokio::sync::Mutex::new(()),
        })
    }

    /// Envia uma requisi√ß√£o para o ChatGPT
    pub async fn send_request(&self, messages: Vec<ChatMessage>) -> crate::Result<ChatResponse> {
        let _rate_limit_guard = self.rate_limiter.lock().await;

        // Rate limiting
        sleep(Duration::from_millis(
            1000 / self.config.rate_limit_rps as u64,
        ))
        .await;

        let request = ChatRequest {
            model: self.config.model.clone(),
            messages,
            temperature: self.config.temperature,
            max_tokens: Some(4000), // Limite razo√°vel para respostas
        };

        debug!("Enviando requisi√ß√£o para ChatGPT: {:?}", request);

        let response = self
            .client
            .post(&self.config.openai_base_url)
            .header(
                "Authorization",
                format!("Bearer {}", self.config.openai_api_key),
            )
            .header("Content-Type", "application/json")
            .json(&request)
            .send()
            .await
            .map_err(|e| {
                error!("Erro na requisi√ß√£o HTTP: {}", e);
                crate::Error::Http(e)
            })?;

        if !response.status().is_success() {
            let status = response.status();
            let error_text = response
                .text()
                .await
                .unwrap_or_else(|_| "Erro desconhecido".to_string());

            error!("Erro na resposta do ChatGPT: {} - {}", status, error_text);

            return match status.as_u16() {
                429 => Err(crate::Error::RateLimit),
                401 => Err(crate::Error::Authentication(
                    "Chave API inv√°lida".to_string(),
                )),
                400 => Err(crate::Error::ChatGPT(format!(
                    "Requisi√ß√£o inv√°lida: {}",
                    error_text
                ))),
                _ => Err(crate::Error::ChatGPT(format!(
                    "Erro HTTP {}: {}",
                    status, error_text
                ))),
            };
        }

        let chat_response: ChatResponse = response.json().await.map_err(|e| {
            error!("Erro ao deserializar resposta: {}", e);
            crate::Error::Http(e)
        })?;

        info!(
            "Resposta recebida do ChatGPT. Tokens usados: {}/{}",
            chat_response.usage.total_tokens, self.config.max_payload_tokens
        );

        Ok(chat_response)
    }

    /// Analisa um chunk de c√≥digo com o ChatGPT e retorna relat√≥rio Markdown
    pub async fn analyze_code_chunk(
        &self,
        chunk_content: &str,
        file_info: &str,
    ) -> crate::Result<String> {
        let system_message = ChatMessage {
            role: "system".to_string(),
            content: self.get_system_prompt().to_string(),
        };

        let user_message = ChatMessage {
            role: "user".to_string(),
            content: format!(
                "Analise o seguinte c√≥digo e forne√ßa um relat√≥rio completo em Markdown:\n\n{}\n\n{}",
                file_info, chunk_content
            ),
        };

        let messages = vec![system_message, user_message];

        let response = self.send_request(messages).await?;

        if let Some(choice) = response.choices.first() {
            let content = &choice.message.content;
            return Ok(content.clone());
        }

        Err(crate::Error::ChatGPT(
            "Nenhuma resposta v√°lida recebida".to_string(),
        ))
    }

    /// Obt√©m o prompt do sistema
    fn get_system_prompt(&self) -> &str {
        r#"Voc√™ √© um especialista em seguran√ßa de c√≥digo e an√°lise est√°tica. 
Sua tarefa √© analisar c√≥digo Python e identificar vulnerabilidades de seguran√ßa, 
problemas de qualidade e oportunidades de melhoria.

IMPORTANTE: Voc√™ deve retornar um relat√≥rio completo formatado em MARKDOWN, n√£o JSON.

O relat√≥rio deve incluir:

# Relat√≥rio de An√°lise de Seguran√ßa - CodeQL + ChatGPT

**Data:** [Data atual]  
**Vers√£o:** 0.1.0  
**Gerado por:** Code Report

---

## üìä Resumo Executivo

### Estat√≠sticas Gerais
- **Total de achados:** [n√∫mero]
- **Arquivos com problemas:** [n√∫mero]
- **Score de risco m√©dio:** [0.0-1.0]

### Distribui√ß√£o por Severidade
- üî¥ **Alta:** [n√∫mero] problemas
- üü° **M√©dia:** [n√∫mero] problemas  
- üü¢ **Baixa:** [n√∫mero] problemas

### Principais Descobertas
[Lista dos principais problemas encontrados]

---

## üìà Estat√≠sticas do CodeQL

- **Total de resultados:** [n√∫mero]
- **Arquivos com problemas:** [n√∫mero]

### Distribui√ß√£o por Severidade
- üî¥ **Alta:** [n√∫mero] problemas
- üü° **M√©dia:** [n√∫mero] problemas
- üü¢ **Baixa:** [n√∫mero] problemas

---

## üîç Achados Detalhados

### [Nome do Arquivo] - Linha [X]

**Problema:** [Descri√ß√£o do problema]
**Severidade:** [Alta/M√©dia/Baixa]
**Categoria:** [Seguran√ßa/Qualidade/Performance]
**Impacto:** [Descri√ß√£o do impacto]
**Recomenda√ß√£o:** [Como corrigir]

**C√≥digo Problem√°tico:**
```python
[linha espec√≠fica do c√≥digo com problema]
```

**C√≥digo Corrigido:**
```python
[c√≥digo corrigido com explica√ß√£o]
```

**Contexto do Problema:**
- **Arquivo:** [nome do arquivo]
- **Linha:** [n√∫mero da linha]
- **Fun√ß√£o:** [nome da fun√ß√£o se aplic√°vel]
- **Severidade:** [Alta/M√©dia/Baixa]
- **CWE:** [CWE-ID se aplic√°vel]

---

## üí° Recomenda√ß√µes

### üî¥ Prioridade Alta (Imediata)
[Lista de recomenda√ß√µes cr√≠ticas]

### üü° Prioridade M√©dia (Pr√≥ximas 2 semanas)
[Lista de recomenda√ß√µes importantes]

### üü¢ Prioridade Baixa (Pr√≥ximo m√™s)
[Lista de melhorias gerais]

---

## üéØ Plano de A√ß√£o

### üî¥ Prioridade Alta (Imediata)
- [ ] [A√ß√£o espec√≠fica]
- [ ] [A√ß√£o espec√≠fica]

### üü° Prioridade M√©dia (Pr√≥ximas 2 semanas)
- [ ] [A√ß√£o espec√≠fica]
- [ ] [A√ß√£o espec√≠fica]

### üü¢ Prioridade Baixa (Pr√≥ximo m√™s)
- [ ] [A√ß√£o espec√≠fica]
- [ ] [A√ß√£o espec√≠fica]

---

## üìã Metadados

**Configura√ß√µes utilizadas:**
- Modelo: gpt-3.5-turbo
- Temperatura: 0.2
- Rate limit: 30 req/s
- Timeout: 30s

---
*Relat√≥rio gerado automaticamente pelo Code Report v0.1.0*

Seja objetivo, t√©cnico e acion√°vel. Priorize seguran√ßa e qualidade. Use emojis e formata√ß√£o Markdown para melhor legibilidade."
  ],
  "risk_score": 0.75
}

Seja objetivo, t√©cnico e acion√°vel. Priorize seguran√ßa e qualidade."#
    }

    /// Tenta extrair an√°lise JSON da resposta
    fn parse_analysis_from_response(&self, content: &str) -> crate::Result<ChatGPTAnalysis> {
        // Procura por blocos JSON na resposta
        if let Some(json_start) = content.find('{') {
            if let Some(json_end) = content.rfind('}') {
                let json_str = &content[json_start..=json_end];

                match serde_json::from_str::<ChatGPTAnalysis>(json_str) {
                    Ok(analysis) => return Ok(analysis),
                    Err(e) => {
                        debug!("Erro ao parsear JSON: {}", e);
                    }
                }
            }
        }

        Err(crate::Error::InvalidFormat(
            "JSON n√£o encontrado na resposta".to_string(),
        ))
    }

    /// Cria uma an√°lise b√°sica quando n√£o consegue extrair JSON
    fn create_basic_analysis(&self, content: &str) -> ChatGPTAnalysis {
        ChatGPTAnalysis {
            findings: vec![],
            summary: content.to_string(),
            recommendations: vec![Recommendation {
                priority: "medium".to_string(),
                title: "An√°lise manual necess√°ria".to_string(),
                description: "N√£o foi poss√≠vel extrair an√°lise estruturada da resposta do ChatGPT"
                    .to_string(),
                effort: "1-2 horas".to_string(),
                impact: "M√©dio".to_string(),
                steps: vec!["Revisar manualmente o c√≥digo".to_string()],
            }],
            confidence_score: 0.5,
        }
    }
}
